"""Floor Plan Recognition Service.

–ì–∏–±—Ä–∏–¥–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–ª–∞–Ω–æ–≤ –ø–æ–º–µ—â–µ–Ω–∏–π.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç SAM 2.1 Large –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–æ–º–Ω–∞—Ç –∏ Hough Transform –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç–µ–Ω.

–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
    - –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (CLAHE, bilateral filter, Otsu+Adaptive thresholding)
    - –î–µ—Ç–µ–∫—Ü–∏—è —Å—Ç–µ–Ω —á–µ—Ä–µ–∑ Probabilistic Hough Transform
    - –î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–Ω–∞—Ç —á–µ—Ä–µ–∑ OCR –ø–ª–æ—â–∞–¥–µ–π + Watershed
    - Fallback –¥–µ—Ç–µ–∫—Ü–∏—è —á–µ—Ä–µ–∑ SAM 2.1 Large

–ê–≤—Ç–æ—Ä: –°—Ç—Ä–µ–∫–æ–ª–æ–≤—Å–∫–∏–π –ú–∞–∫—Å–∏–º –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á
–ó–∞–∫–∞–∑—á–∏–∫: –û–û–û Refloor
–î–∞—Ç–∞: 10.12.2025
–í–µ—Ä—Å–∏—è: 1.0
"""
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import numpy as np
import cv2
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import ORJSONResponse
import orjson

# SAM 2 imports via Ultralytics (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤)
try:
    from ultralytics import SAM
    SAM2_AVAILABLE = True
except ImportError:
    SAM2_AVAILABLE = False
    print("‚ùå Ultralytics not installed. Run: pip install ultralytics")

app = FastAPI(title="Floor Plan Service")

# Global models
sam_model = None


def init_sam2():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ SAM 2.1 Large.
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å SAM 2.1 Large –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
    –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ (224MB) —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    –∏ –∫—ç—à–∏—Ä—É—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π.
    
    Returns:
        SAM: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å SAM 2.1 Large –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
    Raises:
        Exception: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    """
    global sam_model
    
    if not SAM2_AVAILABLE:
        print("‚ùå SAM2 not available")
        return None
    
    try:
        # SAM 2.1 Large (224MB) - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø —Ç–æ—á–Ω–æ—Å—Ç—å (latest 2024)
        # –í–µ—Å–∞ —Å–∫–∞—á–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ, –ø–æ—Ç–æ–º –±—É–¥—É—Ç –≤ –∫—ç—à–µ
        sam_model = SAM('sam2.1_l.pt')
        print(f"‚úÖ SAM 2.1 Large initialized (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)")
        return sam_model
    except Exception as e:
        print(f"‚ùå SAM2 init failed: {e}")
        return None


def preprocess(image: np.ndarray) -> np.ndarray:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–ª–∞–Ω–∞.
    
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:
    1. CLAHE (Contrast Limited Adaptive Histogram Equalization) –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    2. Bilateral filter –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥—Ä–∞–Ω–∏—Ü
    3. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–æ–º–±–∏–Ω–∞—Ü–∏—é Otsu –∏ Adaptive thresholding
    4. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —à—É–º–∞
    
    Args:
        image: –í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ BGR –∏–ª–∏ grayscale —Ñ–æ—Ä–º–∞—Ç–µ
        
    Returns:
        np.ndarray: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (255 = –æ–±—ä–µ–∫—Ç, 0 = —Ñ–æ–Ω)
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
    
    # Multi-scale CLAHE
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # Bilateral filter (edge-preserving)
    bilateral = cv2.bilateralFilter(enhanced, d=9, sigmaColor=75, sigmaSpace=75)
    
    # Otsu + Adaptive fusion
    _, otsu = cv2.threshold(bilateral, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    adapt = cv2.adaptiveThreshold(bilateral, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 10)
    binary = cv2.bitwise_and(otsu, adapt)
    
    # Morphological cleanup
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
    
    return binary


def detect_walls(binary: np.ndarray) -> List[Dict]:
    """–î–µ—Ç–µ–∫—Ü–∏—è —Å—Ç–µ–Ω –Ω–∞ –ø–ª–∞–Ω–µ –ø–æ–º–µ—â–µ–Ω–∏—è.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π Probabilistic Hough Transform –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
    –≤—Å–µ—Ö –ª–∏–Ω–∏–π –Ω–∞ –ø–ª–∞–Ω–µ (–≤–Ω–µ—à–Ω–∏–µ –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç–µ–Ω—ã).
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –°–∫–µ–ª–µ—Ç–∏–∑–∞—Ü–∏—è –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (scikit-image thin)
    2. Probabilistic Hough Transform —Å –Ω–∏–∑–∫–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    3. Snap to axis (–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ 0¬∞/45¬∞/90¬∞/135¬∞)
    4. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    5. –°–ª–∏—è–Ω–∏–µ –∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    
    Args:
        binary: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ (255 = –æ–±—ä–µ–∫—Ç, 0 = —Ñ–æ–Ω)
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å—Ç–µ–Ω, –∫–∞–∂–¥–∞—è —Å—Ç–µ–Ω–∞ - dict —Å –∫–ª—é—á–∞–º–∏:
            - "id": str, —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, "w1")
            - "points": List[[x, y]], –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–æ–Ω—Ü–æ–≤ —Å—Ç–µ–Ω—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö
    """
    # –†–∞–±–æ—Ç–∞–µ–º —Å –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º (—Å—Ç–µ–Ω—ã = —á–µ—Ä–Ω—ã–µ –ª–∏–Ω–∏–∏)
    from skimage.morphology import thin
    skeleton = (thin(binary == 0) * 255).astype(np.uint8)
    
    # –ê–ì–†–ï–°–°–ò–í–ù–´–ô Hough –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –í–°–ï–• –ª–∏–Ω–∏–π (–≤–∫–ª—é—á–∞—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç–µ–Ω—ã)
    lines = cv2.HoughLinesP(
        skeleton, 
        rho=1, 
        theta=np.pi/180, 
        threshold=30,      # –°–ù–ò–ñ–ï–ù –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Ç–µ–Ω
        minLineLength=20,  # –°–ù–ò–ñ–ï–ù –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ç–µ–Ω
        maxLineGap=35      # –£–í–ï–õ–ò–ß–ï–ù –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–∞–∑—Ä—ã–≤–æ–≤
    )
    
    segments = []
    if lines is not None:
        for x1, y1, x2, y2 in lines[:, 0]:
            length = np.hypot(x2 - x1, y2 - y1)
            if length >= 15:  # –ú–∏–Ω–∏–º—É–º 15px (–∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç–µ–Ω—ã)
                x1, y1, x2, y2 = snap_to_axis(x1, y1, x2, y2)
                segments.append({"points": [[int(x1), int(y1)], [int(x2), int(y2)]]})
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_segments = []
    for seg in segments:
        is_duplicate = False
        for useg in unique_segments:
            dist1 = np.hypot(seg["points"][0][0] - useg["points"][0][0], seg["points"][0][1] - useg["points"][0][1])
            dist2 = np.hypot(seg["points"][1][0] - useg["points"][1][0], seg["points"][1][1] - useg["points"][1][1])
            if dist1 < 15 and dist2 < 15:
                is_duplicate = True
                break
        if not is_duplicate:
            unique_segments.append(seg)
    
    # Merge collinear (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–µ–Ω)
    merged = merge_segments(unique_segments, max_angle=3.0, max_gap=50.0)
    
    print(f"üî¥ Detected {len(merged)} walls (after merging from {len(unique_segments)} segments)")
    return [{"id": f"w{i+1}", **seg} for i, seg in enumerate(merged)]


def detect_rooms_sam2(image: np.ndarray, binary: np.ndarray) -> List[Dict]:
    """–î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–Ω–∞—Ç —á–µ—Ä–µ–∑ SAM 2.1 Large —Å –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é SAM2 –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫—Ä—É–ø–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (–∫–æ–º–Ω–∞—Ç)
    —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–≥–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –º–µ–±–µ–ª–∏, —Ç–µ–∫—Å—Ç–∞ –∏ –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤.
    
    –§–∏–ª—å—Ç—Ä—ã:
    1. –ü–ª–æ—â–∞–¥—å –º–∞—Å–∫–∏: 3000 < area < 60% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    2. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞: > 4000 –ø–∏–∫—Å–µ–ª–µ–π
    3. Aspect ratio: < 5 (–Ω–µ –≤—ã—Ç—è–Ω—É—Ç—ã–µ –æ–±—ä–µ–∫—Ç—ã)
    4. Solidity: > 0.75 (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ —Ñ–æ—Ä–º—ã)
    5. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–≥–ª–æ–≤: 3-12 (–º–Ω–æ–≥–æ—É–≥–æ–ª—å–Ω–∏–∫–∏)
    
    Args:
        image: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ BGR —Ñ–æ—Ä–º–∞—Ç–µ
        binary: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é)
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –∫–æ–º–Ω–∞—Ç —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏, –ø–ª–æ—â–∞–¥—è–º–∏ –∏ confidence scores
        
    Note:
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback –µ—Å–ª–∏ OCR –Ω–∞—à–µ–ª < 5 –∫–æ–º–Ω–∞—Ç
    """
    if sam_model is None:
        return detect_rooms_fallback(binary)
    
    try:
        # SAM2 –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        results = sam_model(
            image, 
            retina_masks=True,
            imgsz=1024,
            conf=0.4,  # –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—Å–µ—Ö –∫–æ–º–Ω–∞—Ç
            iou=0.9,   # –í—ã—Å–æ–∫–∏–π IOU —á—Ç–æ–±—ã –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —Å–æ—Å–µ–¥–Ω–∏–µ –∫–æ–º–Ω–∞—Ç—ã
        )
        
        all_masks = []
        for result in results:
            if result.masks is None:
                continue
            
            for idx, mask in enumerate(result.masks.data):
                mask_np = mask.cpu().numpy() if hasattr(mask, 'cpu') else mask
                mask_uint8 = (mask_np * 255).astype(np.uint8)
                
                # –°—Ä–∞–∑—É –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –º–∞—Å–∫–∏
                area = cv2.countNonZero(mask_uint8)
                img_area = mask_uint8.shape[0] * mask_uint8.shape[1]
                
                # –§–ò–õ–¨–¢–†: —Å—Ä–µ–¥–Ω–∏–µ –∏ –±–æ–ª—å—à–∏–µ –æ–±–ª–∞—Å—Ç–∏ (–∫–æ–º–Ω–∞—Ç—ã), –Ω–µ –º–µ–±–µ–ª—å –∏ –Ω–µ –≤—Å—è –∫–≤–∞—Ä—Ç–∏—Ä–∞
                if area < 3000 or area > img_area * 0.6:
                    continue
                
                conf = result.masks.conf[idx].item() if hasattr(result.masks, 'conf') else 0.9
                all_masks.append({
                    "mask": mask_uint8,
                    "area": area,
                    "confidence": float(conf)
                })
        
        print(f"üìä SAM2 found {len(all_masks)} large areas (potential rooms)")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–∞—Å–∫–∏ –≤ –ø–æ–ª–∏–≥–æ–Ω—ã —Å –£–ú–ù–û–ô —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        rooms = []
        for mask_data in all_masks:
            mask = mask_data["mask"]
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # –§–∏–ª—å—Ç—Ä 1: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å (–ù–ï –º–µ–±–µ–ª—å)
                if area < 4000:
                    continue
                
                # –§–∏–ª—å—Ç—Ä 2: Aspect ratio (–∫–æ–º–Ω–∞—Ç—ã –ù–ï —Å–ª–∏—à–∫–æ–º –≤—ã—Ç—è–Ω—É—Ç—ã–µ)
                rect = cv2.minAreaRect(contour)
                width, height = rect[1]
                if width > 0 and height > 0:
                    aspect_ratio = max(width, height) / min(width, height)
                    if aspect_ratio > 5:  # –°–ª–∏—à–∫–æ–º –≤—ã—Ç—è–Ω—É—Ç—ã–π –æ–±—ä–µ–∫—Ç (—Ç—Ä—É–±–∞, —Å—Ç–µ–Ω–∞)
                        continue
                
                # –§–∏–ª—å—Ç—Ä 3: Solidity (–∫–æ–º–Ω–∞—Ç—ã - —ç—Ç–æ solid shapes)
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                if hull_area > 0:
                    solidity = area / hull_area
                    if solidity < 0.75:  # –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è —Ñ–æ—Ä–º–∞ (–º–µ–±–µ–ª—å)
                        continue
                
                # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è –ø–æ–ª–∏–≥–æ–Ω–∞
                epsilon = 0.012 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # –§–∏–ª—å—Ç—Ä 4: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–≥–ª–æ–≤ (–∫–æ–º–Ω–∞—Ç—ã –∏–º–µ—é—Ç 3-12 —É–≥–ª–æ–≤)
                if not (3 <= len(approx) <= 12):
                    continue
                
                polygon = [[int(p[0][0]), int(p[0][1])] for p in approx]
                rooms.append({
                    "id": f"r{len(rooms)+1}",
                    "polygon": polygon,
                    "area": int(area),
                    "confidence": mask_data["confidence"]
                })
        
        print(f"‚úÖ SAM2 detected {len(rooms)} rooms")
        return rooms if rooms else detect_rooms_fallback(binary)
    
    except Exception as e:
        print(f"‚ö†Ô∏è SAM2 failed: {e}, using fallback")
        return detect_rooms_fallback(binary)


def detect_rooms_by_labels(image: np.ndarray, binary: np.ndarray) -> List[Dict]:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–Ω–∞—Ç —á–µ—Ä–µ–∑ OCR –ø–ª–æ—â–∞–¥–µ–π.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç EasyOCR –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–ª–æ—â–∞–¥–µ–π –∫–æ–º–Ω–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, "7.9", "12.6")
    –Ω–∞ –ø–ª–∞–Ω–µ –ë–¢–ò –∏ —Å—Ç—Ä–æ–∏—Ç –ø–æ–ª–∏–≥–æ–Ω—ã –∫–æ–º–Ω–∞—Ç —á–µ—Ä–µ–∑ Watershed –æ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ü–µ–Ω—Ç—Ä–æ–≤.
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–ª–∞–Ω–µ (EasyOCR)
    2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –ø–æ–∏—Å–∫ —á–∏—Å–µ–ª –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0.8-20 –º¬≤ (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø–ª–æ—â–∞–¥–∏ –∫–æ–º–Ω–∞—Ç)
    3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π (k=, h=, —Ä–∞–∑–º–µ—Ä—ã)
    4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–ª–æ—â–∞–¥–µ–π –∫–∞–∫ —Ü–µ–Ω—Ç—Ä–æ–≤ –∫–æ–º–Ω–∞—Ç
    5. Watershed —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –æ—Ç —Ü–µ–Ω—Ç—Ä–æ–≤
    6. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ area –∏ aspect ratio
    
    Args:
        image: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –≤ BGR —Ñ–æ—Ä–º–∞—Ç–µ
        binary: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–∞
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –∫–æ–º–Ω–∞—Ç, –∫–∞–∂–¥–∞—è –∫–æ–º–Ω–∞—Ç–∞ - dict —Å –∫–ª—é—á–∞–º–∏:
            - "id": str, —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, "r1")
            - "polygon": List[[x, y]], –≤–µ—Ä—à–∏–Ω—ã –ø–æ–ª–∏–≥–æ–Ω–∞ –∫–æ–º–Ω–∞—Ç—ã
            - "area": int, –ø–ª–æ—â–∞–¥—å –∫–æ–º–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö¬≤
            - "label": str, —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–ª–æ—â–∞–¥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "7.9")
            - "area_sqm": float, –ø–ª–æ—â–∞–¥—å –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∞—Ö
    """
    try:
        import easyocr
        reader = easyocr.Reader(['ru', 'en'], gpu=False, verbose=False)
        
        # OCR –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        results = reader.readtext(image)
        
        # –ò—â–µ–º —á–∏—Å–ª–∞ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –ø–ª–æ—â–∞–¥–∏ –∫–æ–º–Ω–∞—Ç (–°–¢–†–û–ì–ò–ô —Ñ–∏–ª—å—Ç—Ä)
        room_centers = []
        for (bbox, text, conf) in results:
            # –ò–°–ö–õ–Æ–ß–ê–ï–ú —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è (k=, h=, w=, –∏ —Ç.–¥.)
            if any(x in text.lower() for x in ['k=', 'h=', 'w=', '—Ö', '√ó']):
                continue
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ
            import re
            numbers = re.findall(r'\d+\.?\d*', text)
            
            # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –û–î–ù–û —á–∏—Å–ª–æ (—á–∏—Å—Ç–∞—è –ø–ª–æ—â–∞–¥—å, –Ω–µ "3.96")
            if len(numbers) != 1:
                continue
            
            try:
                area_sqm = float(numbers[0])
                # –°–¢–†–û–ì–ò–ô —Ñ–∏–ª—å—Ç—Ä: —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø–ª–æ—â–∞–¥–∏ –ö–û–ú–ù–ê–¢ (0.8-20 –º¬≤)
                # –í–∫–ª—é—á–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–æ–º–µ—â–µ–Ω–∏—è (–≤–∞–Ω–Ω–∞—è, –∫–æ—Ä–∏–¥–æ—Ä, –∫–ª–∞–¥–æ–≤–∫–∞)
                if 0.8 <= area_sqm <= 20:
                    # –¶–µ–Ω—Ç—Ä bbox = —Ü–µ–Ω—Ç—Ä –∫–æ–º–Ω–∞—Ç—ã
                    x_center = int((bbox[0][0] + bbox[2][0]) / 2)
                    y_center = int((bbox[0][1] + bbox[2][1]) / 2)
                    room_centers.append({
                        "center": [x_center, y_center],
                        "area_sqm": area_sqm,
                        "text": text
                    })
                    print(f"  üìç Found room label: {text} at ({x_center}, {y_center})")
            except:
                continue
        
        print(f"üè† Found {len(room_centers)} room labels via OCR")
        
        if not room_centers:
            return []
        
        # –°—Ç—Ä–æ–∏–º –ø–æ–ª–∏–≥–æ–Ω—ã –∫–æ–º–Ω–∞—Ç –∏—Å–ø–æ–ª—å–∑—É—è watershed –æ—Ç —Ü–µ–Ω—Ç—Ä–æ–≤
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º (–∫–æ–º–Ω–∞—Ç—ã = –±–µ–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏)
        binary_inv = cv2.bitwise_not(binary)
        
        # –ê–ì–†–ï–°–°–ò–í–ù–û–ï –∑–∞–∫—Ä—ã—Ç–∏–µ —Ä–∞–∑—Ä—ã–≤–æ–≤ –≤ —Å—Ç–µ–Ω–∞—Ö (—á—Ç–æ–±—ã –∫–æ–º–Ω–∞—Ç—ã –±—ã–ª–∏ –∑–∞–º–∫–Ω—É—Ç—ã)
        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
        binary_inv = cv2.morphologyEx(binary_inv, cv2.MORPH_CLOSE, kernel_close, iterations=3)
        
        # Distance transform
        dist = cv2.distanceTransform(binary_inv, cv2.DIST_L2, 5)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è watershed
        markers = np.zeros(binary.shape, dtype=np.int32)
        for idx, room_center in enumerate(room_centers):
            cx, cy = room_center["center"]
            markers[cy, cx] = idx + 1
        
        # Watershed
        bgr_img = cv2.cvtColor(binary_inv, cv2.COLOR_GRAY2BGR)
        cv2.watershed(bgr_img, markers)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç—É—Ä—ã –∫–æ–º–Ω–∞—Ç —Å –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô
        rooms = []
        img_area = binary.shape[0] * binary.shape[1]
        
        for idx, room_center in enumerate(room_centers):
            mask = (markers == idx + 1).astype(np.uint8) * 255
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # –§–ò–õ–¨–¢–†: –∫–æ–º–Ω–∞—Ç–∞ –ù–ï –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–π –∏–ª–∏ –û–ì–†–û–ú–ù–û–ô
                if area < 2000:
                    continue
                
                # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–õ–¨–¢–†: –∫–æ–º–Ω–∞—Ç–∞ –ù–ï –¥–æ–ª–∂–Ω–∞ –∑–∞–Ω–∏–º–∞—Ç—å > 40% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                # (SAM2 –∏–Ω–æ–≥–¥–∞ –æ–±–≤–æ–¥–∏—Ç –≤—Å—é –∫–≤–∞—Ä—Ç–∏—Ä—É)
                if area > img_area * 0.4:
                    print(f"  ‚ö†Ô∏è Rejected room {idx+1}: too large ({area}/{img_area} = {area/img_area:.1%})")
                    continue
                
                epsilon = 0.015 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                if len(approx) >= 3:
                    polygon = [[int(p[0][0]), int(p[0][1])] for p in approx]
                    rooms.append({
                        "id": f"r{len(rooms)+1}",
                        "polygon": polygon,
                        "area": int(area),
                        "label": room_center["text"],
                        "area_sqm": room_center["area_sqm"]
                    })
        
        print(f"‚úÖ Built {len(rooms)} room polygons from OCR labels")
        return rooms
    
    except Exception as e:
        print(f"‚ö†Ô∏è OCR-based room detection failed: {e}")
        return []


def detect_rooms_fallback(binary: np.ndarray) -> List[Dict]:
    """Fallback –¥–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–Ω–∞—Ç —á–µ—Ä–µ–∑ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ SAM2 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ OCR –Ω–µ –Ω–∞—à–µ–ª –∫–æ–º–Ω–∞—Ç—ã.
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∑–∞–º—ã–∫–∞–Ω–∏—è —Ä–∞–∑—Ä—ã–≤–æ–≤ –≤ —Å—Ç–µ–Ω–∞—Ö
    –∏ –ø–æ–∏—Å–∫–∞ –∑–∞–º–∫–Ω—É—Ç—ã—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤ (–∫–æ–º–Ω–∞—Ç).
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Ä–∞–∑—Ä—ã–≤–æ–≤ (MORPH_CLOSE)
    2. –ò–Ω–≤–µ—Ä—Å–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫–æ–º–Ω–∞—Ç—ã = –±–µ–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏)
    3. –£–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞ (MORPH_OPEN)
    4. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤ —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π (RETR_TREE)
    5. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–ª–æ—â–∞–¥–∏, –∏–µ—Ä–∞—Ä—Ö–∏–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–≥–ª–æ–≤
    
    Args:
        binary: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–∞
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –∫–æ–º–Ω–∞—Ç —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏ –∏ –ø–ª–æ—â–∞–¥—è–º–∏
    """
    # –ó–∞–∫—Ä—ã—Ç–∏–µ —Ä–∞–∑—Ä—ã–≤–æ–≤ (—É–º–µ—Ä–µ–Ω–Ω–æ–µ)
    kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close, iterations=5)
    
    # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º (–∫–æ–º–Ω–∞—Ç—ã = –±–µ–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏)
    binary_inv = cv2.bitwise_not(closed)
    
    # –£–±–∏—Ä–∞–µ–º –º–µ–ª–∫–∏–π —à—É–º
    kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    binary_inv = cv2.morphologyEx(binary_inv, cv2.MORPH_OPEN, kernel_open, iterations=2)
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π
    contours, hierarchy = cv2.findContours(binary_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    
    print(f"üìä Found {len(contours)} total contours")
    
    rooms = []
    img_area = binary.shape[0] * binary.shape[1]
    
    for idx, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –ø–ª–æ—â–∞–¥–∏ (–±–æ–ª–µ–µ –º—è–≥–∫–∏–π)
        if not (1000 < area < img_area * 0.9):
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—é
        parent = hierarchy[0][idx][3]
        if parent == -1 and area < 5000:  # –¢–æ–ª—å–∫–æ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –±–µ–∑ —Ä–æ–¥–∏—Ç–µ–ª—è –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
        
        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è –ø–æ–ª–∏–≥–æ–Ω–∞
        epsilon = 0.015 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        if len(approx) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —É–≥–ª–∞
            polygon = [[int(p[0][0]), int(p[0][1])] for p in approx]
            rooms.append({
                "id": f"r{len(rooms)+1}",
                "polygon": polygon,
                "area": int(area)
            })
            print(f"  ‚úì Room {len(rooms)}: area={area:.0f}, corners={len(approx)}, parent={parent}")
    
    print(f"‚úÖ Detected {len(rooms)} rooms")
    return rooms


def snap_to_axis(x1: float, y1: float, x2: float, y2: float) -> Tuple[int, int, int, int]:
    """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ª–∏–Ω–∏–∏ –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —É–≥–ª–∞–º (0¬∞/45¬∞/90¬∞/135¬∞).
    
    –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–æ–Ω—Ü–æ–≤ –ª–∏–Ω–∏–∏ —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ —Å—Ç—Ä–æ–≥–æ
    –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–π, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –∏–ª–∏ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ–π (45¬∞/135¬∞).
    –£–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç–µ–Ω –Ω–∞ –ø–ª–∞–Ω–∞—Ö.
    
    Args:
        x1, y1: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏
        x2, y2: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—Ç–æ—Ä–æ–π —Ç–æ—á–∫–∏
        
    Returns:
        Tuple[int, int, int, int]: –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (x1, y1, x2, y2)
    """
    dx, dy = x2 - x1, y2 - y1
    length = np.hypot(dx, dy)
    if length < 1:
        return int(x1), int(y1), int(x2), int(y2)
    
    angle = np.degrees(np.arctan2(dy, dx)) % 180
    
    if abs(angle) < 5 or abs(angle - 180) < 5:
        y2 = y1
    elif abs(angle - 90) < 5:
        x2 = x1
    elif abs(angle - 45) < 5:
        avg = (abs(dx) + abs(dy)) / 2
        x2 = x1 + (avg if dx > 0 else -avg)
        y2 = y1 + (avg if dy > 0 else -avg)
    elif abs(angle - 135) < 5:
        avg = (abs(dx) + abs(dy)) / 2
        x2 = x1 + (avg if dx > 0 else -avg)
        y2 = y1 - (avg if dy > 0 else -avg)
    
    return int(x1), int(y1), int(x2), int(y2)


def merge_segments(segments: List[Dict], max_angle: float, max_gap: float) -> List[Dict]:
    """–°–ª–∏—è–Ω–∏–µ –∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å—Ç–µ–Ω.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–Ω–∏–∏ —Å—Ç–µ–Ω –≤ –µ–¥–∏–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≥–ª–∞ –º–µ–∂–¥—É –Ω–∏–º–∏ –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –∫–æ–Ω—Ü–∞–º–∏.
    
    Args:
        segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å—Ç–µ–Ω
        max_angle: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è —Å–ª–∏—è–Ω–∏—è (–≥—Ä–∞–¥—É—Å—ã)
        max_gap: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–æ–Ω—Ü–∞–º–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–ø–∏–∫—Å–µ–ª–∏)
        
    Returns:
        List[Dict]: –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å—Ç–µ–Ω
    """
    if not segments:
        return []
    
    merged = []
    used = [False] * len(segments)
    
    for i, seg1 in enumerate(segments):
        if used[i]:
            continue
        
        p1, p2 = seg1["points"]
        pts = [p1, p2]
        used[i] = True
        
        for j, seg2 in enumerate(segments):
            if used[j] or i == j:
                continue
            
            p3, p4 = seg2["points"]
            angle_diff = angle_between(p1, p2, p3, p4)
            dist = min(
                np.hypot(p2[0]-p3[0], p2[1]-p3[1]),
                np.hypot(p2[0]-p4[0], p2[1]-p4[1]),
                np.hypot(p1[0]-p3[0], p1[1]-p3[1]),
                np.hypot(p1[0]-p4[0], p1[1]-p4[1]),
            )
            
            if angle_diff < max_angle and dist < max_gap:
                pts.extend([p3, p4])
                used[j] = True
        
        if len(pts) > 2:
            pts_arr = np.array(pts)
            dists = np.linalg.norm(pts_arr[:, None] - pts_arr[None, :], axis=2)
            i_max, j_max = np.unravel_index(dists.argmax(), dists.shape)
            pts = [pts[i_max], pts[j_max]]
        
        merged.append({"points": pts})
    
    return merged


def angle_between(p1, p2, p3, p4) -> float:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏.
    
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –¥–≤—É—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    —á–µ—Ä–µ–∑ —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ.
    
    Args:
        p1, p2: –ö–æ–Ω—Ü—ã –ø–µ—Ä–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ [x, y]
        p3, p4: –ö–æ–Ω—Ü—ã –≤—Ç–æ—Ä–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ [x, y]
        
    Returns:
        float: –£–≥–æ–ª –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –≤ –≥—Ä–∞–¥—É—Å–∞—Ö (0-90¬∞)
    """
    v1 = np.array([p2[0] - p1[0], p2[1] - p1[1]])
    v2 = np.array([p4[0] - p3[0], p4[1] - p3[1]])
    n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)
    if n1 < 1e-6 or n2 < 1e-6:
        return 180.0
    cos_angle = np.clip(np.dot(v1, v2) / (n1 * n2), -1.0, 1.0)
    angle = np.degrees(np.arccos(abs(cos_angle)))
    return min(angle, 180 - angle)


def process_image(image_bytes: bytes, source_name: str = "unknown.png") -> Dict:
    """–û—Å–Ω–æ–≤–Ω–æ–π pipeline —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ–º–µ—â–µ–Ω–∏—è.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–ª–∞–Ω–∞:
    1. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ bytes
    2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (CLAHE, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è)
    3. –î–µ—Ç–µ–∫—Ü–∏—è —Å—Ç–µ–Ω (Hough Transform)
    4. –î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–Ω–∞—Ç (OCR –ø–ª–æ—â–∞–¥–µ–π + Watershed, fallback SAM2)
    5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR –∏ SAM2
    
    Args:
        image_bytes: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (JPG/PNG)
        source_name: –ò–º—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        Dict: JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:
            - "meta": Dict —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (source, width, height, model)
            - "walls": List[Dict] —Å–ø–∏—Å–æ–∫ —Å—Ç–µ–Ω —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
            - "rooms": List[Dict] —Å–ø–∏—Å–æ–∫ –∫–æ–º–Ω–∞—Ç —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏ –∏ –ø–ª–æ—â–∞–¥—è–º–∏
            - "error": str (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
    """
    nparr = np.frombuffer(image_bytes, np.uint8)
    bgr = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    if bgr is None:
        return {"error": "Failed to decode image"}
    
    binary = preprocess(bgr)
    
    # –û–°–ù–û–í–ù–ê–Ø –ó–ê–î–ê–ß–ê: –î–µ—Ç–µ–∫—Ü–∏—è —Å—Ç–µ–Ω
    walls = detect_walls(binary)
    
    # –ë–û–ù–£–°: –ö–æ–Ω—Ç—É—Ä—ã –ø–æ–º–µ—â–µ–Ω–∏–π (–£–ú–ù–ê–Ø –¥–µ—Ç–µ–∫—Ü–∏—è —á–µ—Ä–µ–∑ OCR –ø–ª–æ—â–∞–¥–µ–π)
    rooms = detect_rooms_by_labels(bgr, binary)
    
    # –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –ø–æ–¥—Ö–æ–¥: –ï—Å–ª–∏ OCR –Ω–∞—à–µ–ª –º–∞–ª–æ –∫–æ–º–Ω–∞—Ç, –¥–æ–ø–æ–ª–Ω—è–µ–º —á–µ—Ä–µ–∑ SAM2
    if len(rooms) < 5:  # –û–∂–∏–¥–∞–µ–º –º–∏–Ω–∏–º—É–º 5-6 –∫–æ–º–Ω–∞—Ç –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ
        print(f"‚ö†Ô∏è OCR found only {len(rooms)} rooms, adding SAM2 rooms...")
        sam2_rooms = detect_rooms_sam2(bgr, binary)
        
        # –î–æ–±–∞–≤–ª—è–µ–º SAM2 –∫–æ–º–Ω–∞—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Å OCR –∫–æ–º–Ω–∞—Ç–∞–º–∏
        for sam_room in sam2_rooms:
            is_duplicate = False
            sam_poly = np.array(sam_room["polygon"], dtype=np.int32)
            
            for ocr_room in rooms:
                ocr_poly = np.array(ocr_room["polygon"], dtype=np.int32)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø–æ–ª–∏–≥–æ–Ω–æ–≤
                intersection = cv2.intersectConvexConvex(ocr_poly, sam_poly)[1]
                if intersection is not None and cv2.contourArea(intersection) > 1000:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                sam_room["id"] = f"r{len(rooms)+1}"
                rooms.append(sam_room)
                print(f"  ‚ûï Added SAM2 room (area={sam_room['area']})")
    
    print(f"‚úÖ Total rooms detected: {len(rooms)}")
    
    return {
        "meta": {
            "source": source_name
        },
        "walls": walls
    }


@app.on_event("startup")
async def startup():
    init_sam2()
    print("üöÄ Floor Plan Service ready")


@app.post("/detect", response_class=ORJSONResponse)
async def detect(file: UploadFile = File(...)):
    content = await file.read()
    source_name = file.filename if file.filename else "unknown.png"
    result = process_image(content, source_name)
    return result


@app.get("/health")
async def health():
    return {"status": "ok", "sam2_large": sam_model is not None}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
